{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code that was utilized for processing the demultiplexed amplicon sequences. Further processing may have been performed in mothur or R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chunk is for generating a dataframe for the real sequencing data (subsample 100 events) as well as an in silico data set based off of the Poisson distribution (accounting for 16S copy number). The dataframe is outputted into a shared file to be normalized by mothur (same sequencing depth across samples) and generate a principle component analysis chart (PCA). PCA was chosen because the number of dimensions is relatively small, and PCA tends to reduce the variability into 3 dimensions which captures the data better than using a dissimilarity matrix and using a PCoA, which won't capture much of the variability. The resulting PCA is plotted with ggplot in R and then edited with Illustrator to make the figure in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def in_silico_mock(lambdas, label, n_instances, seed, multiplier):\n",
    "# Generate Poisson-distributed data for each lambda\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    lambda_df = pd.DataFrame()\n",
    "\n",
    "    Bs_poisson = np.random.poisson(lambdas[0], n_instances)\n",
    "    Bt_poisson = np.random.poisson(lambdas[1], n_instances)\n",
    "    Ec_poisson = np.random.poisson(lambdas[2], n_instances)\n",
    "    Pp_poisson = np.random.poisson(lambdas[3], n_instances)\n",
    "    \n",
    "    # Create a DataFrame for the current lambda\n",
    "    # Multiply by 16S copy number to account for that\n",
    "    #Multiplier is for subsampling, to increase the number of events from all samples for normalization downstream\n",
    "    lambda_df['Bacillus_subtilis'] = Bs_poisson*10*multiplier\n",
    "    lambda_df['Bacteroides_thetaiotaomicron'] = Bt_poisson*5*multiplier\n",
    "    lambda_df['Escherichia_coli'] = Ec_poisson*7*multiplier\n",
    "    lambda_df['Pseudomonas_putida'] = Pp_poisson*7*multiplier\n",
    "\n",
    "    #lambda_df['Total'] = lambda_df[['Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida']].sum(axis=1)\n",
    "\n",
    "    #lambda_df['Bacillus_subtilis'] = lambda_df['Bacillus_subtilis']/lambda_df['Total']\n",
    "    #lambda_df['Bacteroides_thetaiotaomicron'] = lambda_df['Bacteroides_thetaiotaomicron']/lambda_df['Total']\n",
    "    #lambda_df['Escherichia_coli'] = lambda_df['Escherichia_coli']/lambda_df['Total']\n",
    "    #lambda_df['Pseudomonas_putida'] = lambda_df['Pseudomonas_putida']/lambda_df['Total']\n",
    "\n",
    "    lambda_df['label'] = 'vsearch'\n",
    "    lambda_df['numOtus'] = 4\n",
    "    lambda_df['Group'] = \"silico_%s\" % (label)\n",
    "\n",
    "    #for row_index in lambda_df.index:\n",
    "    #    lambda_df.iat[row_index,7] = row_index+1\n",
    "\n",
    "    #lambda_df = lambda_df.drop('Total', axis='columns')\n",
    "\n",
    "    shared_file_order = ['label', 'Group', 'numOtus', 'Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida' ]\n",
    "    lambda_df = lambda_df[shared_file_order]\n",
    "\n",
    "    return lambda_df\n",
    "\n",
    "#generate in silico mock community\n",
    "# Lambda values (in order of Bs, Bt, Ec, Pp)\n",
    "lambdas_even = [25, 25, 25, 25]\n",
    "lambdas_log1 = [0.8, 90, 0.2, 9]\n",
    "lambdas_log2 = [9, 0.2, 90, 0.8]\n",
    "# generate dummy data to force 4 sided PCA plot\n",
    "#lambdas_log3 = [0.2, 0.8, 9, 90]\n",
    "#lambdas_log4 = [90, 9, 0.8, 0.2]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "silico_even_df = in_silico_mock(lambdas_even, \"even\", 100, 42, 3)\n",
    "silico_log1_df = in_silico_mock(lambdas_log1, \"log1\", 100, 42, 3)\n",
    "silico_log2_df = in_silico_mock(lambdas_log2, \"log2\", 100, 42, 3)\n",
    "#silico_log3_df = in_silico_mock(lambdas_log3, \"log3\", 100, 42, 3)\n",
    "#silico_log4_df = in_silico_mock(lambdas_log4, \"log4\", 100, 42, 3)\n",
    "\n",
    "concat_silico_df = pd.concat([silico_even_df, silico_log1_df, silico_log2_df], axis = 0)\n",
    "#concat_silico_df = pd.concat([silico_even_df, silico_log1_df, silico_log2_df, silico_log3_df, silico_log4_df], axis = 0)\n",
    "#concat_silico_df.to_csv('silico_data.tsv', sep='\\t', index=False)\n",
    "\n",
    "#process the real mock community data\n",
    "even_df = pd.read_csv('even/even.shared', delimiter = '\\t')\n",
    "log1_df = pd.read_csv('log1/log1.shared', delimiter = '\\t')\n",
    "log2_df = pd.read_csv('log2/log2.shared', delimiter = '\\t')\n",
    "                      \n",
    "subsampled_even_df = even_df.sample(n=100, random_state=42)  # random_state for reproducibility\n",
    "subsampled_log1_df = log1_df.sample(n=100, random_state=42)\n",
    "subsampled_log2_df = log2_df.sample(n=100, random_state=42)\n",
    "\n",
    "subsampled_even_df['Group'] = 'even'\n",
    "subsampled_log1_df['Group'] = 'log1'\n",
    "subsampled_log2_df['Group'] = 'log2'\n",
    "\n",
    "concat_subsampled_df = pd.concat([subsampled_even_df, subsampled_log1_df, subsampled_log2_df], axis=0)\n",
    "\n",
    "#Removed 16S copy number and multiplied that in the insilico data to account for it instead\n",
    "concat_subsampled_df['Bacillus_subtilis'] = concat_subsampled_df['Bacillus_subtilis']\n",
    "concat_subsampled_df['Bacteroides_thetaiotaomicron'] = concat_subsampled_df['Bacteroides_thetaiotaomicron']\n",
    "concat_subsampled_df['Escherichia_coli'] = concat_subsampled_df['Escherichia_coli']\n",
    "concat_subsampled_df['Pseudomonas_putida'] = concat_subsampled_df['Pseudomonas_putida']\n",
    "\n",
    "#DO NOT NORMALIZE W/ REL ABUNDANCE, PCA WONT LIKE IT\n",
    "#concat_subsampled_df['Total'] = concat_subsampled_df[['Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida']].sum(axis=1)\n",
    "#concat_subsampled_df['Bacillus_subtilis'] = concat_subsampled_df['Bacillus_subtilis']/concat_subsampled_df['Total']\n",
    "#concat_subsampled_df['Bacteroides_thetaiotaomicron'] = concat_subsampled_df['Bacteroides_thetaiotaomicron']/concat_subsampled_df['Total']\n",
    "#concat_subsampled_df['Escherichia_coli'] = concat_subsampled_df['Escherichia_coli']/concat_subsampled_df['Total']\n",
    "#concat_subsampled_df['Pseudomonas_putida'] = concat_subsampled_df['Pseudomonas_putida']/concat_subsampled_df['Total']\n",
    "#concat_subsampled_df = concat_subsampled_df.drop('Total', axis='columns')\n",
    "#concat_subsampled_df.to_csv('real_data.tsv', sep='\\t', index=False)\n",
    "\n",
    "#vertices of PCA space\n",
    "ref_df = pd.DataFrame({\n",
    "    'label': ['vsearch', 'vsearch', 'vsearch','vsearch'],\n",
    "    'Group': ['Bs', 'Bt', 'Ec','Pp'],\n",
    "    'numOtus': [4, 4, 4, 4],\n",
    "    'Bacillus_subtilis': [1000, 0, 0, 0],\n",
    "    'Bacteroides_thetaiotaomicron': [0, 1000, 0, 0],\n",
    "    'Escherichia_coli': [0, 0, 1000, 0],\n",
    "    'Pseudomonas_putida': [0, 0, 0, 1000]\n",
    "})\n",
    "\n",
    "#combine dataframes into one .shared file to be processed in mothur to subsample and to make the PCA plot\n",
    "combined_data_df = pd.concat([concat_subsampled_df, concat_silico_df, ref_df], axis=0)\n",
    "combined_data_df.to_csv('mock_pca_data.shared', sep='\\t', index=False)\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code chunk converts the abundance dataframe into a presence/absence and then % prevelance and compares to expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def in_silico_mock(lambdas, label, n_instances, seed, multiplier):\n",
    "# Generate Poisson-distributed data for each lambda\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    lambda_df = pd.DataFrame()\n",
    "\n",
    "    Bs_poisson = np.random.poisson(lambdas[0], n_instances)\n",
    "    Bt_poisson = np.random.poisson(lambdas[1], n_instances)\n",
    "    Ec_poisson = np.random.poisson(lambdas[2], n_instances)\n",
    "    Pp_poisson = np.random.poisson(lambdas[3], n_instances)\n",
    "    \n",
    "    # Create a DataFrame for the current lambda\n",
    "    # Multiply by 16S copy number to account for that\n",
    "    #Multiplier is for subsampling, to increase the number of events from all samples for normalization downstream\n",
    "    lambda_df['Bacillus_subtilis'] = Bs_poisson*10*multiplier\n",
    "    lambda_df['Bacteroides_thetaiotaomicron'] = Bt_poisson*5*multiplier\n",
    "    lambda_df['Escherichia_coli'] = Ec_poisson*7*multiplier\n",
    "    lambda_df['Pseudomonas_putida'] = Pp_poisson*7*multiplier\n",
    "\n",
    "    #lambda_df['Total'] = lambda_df[['Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida']].sum(axis=1)\n",
    "\n",
    "    #lambda_df['Bacillus_subtilis'] = lambda_df['Bacillus_subtilis']/lambda_df['Total']\n",
    "    #lambda_df['Bacteroides_thetaiotaomicron'] = lambda_df['Bacteroides_thetaiotaomicron']/lambda_df['Total']\n",
    "    #lambda_df['Escherichia_coli'] = lambda_df['Escherichia_coli']/lambda_df['Total']\n",
    "    #lambda_df['Pseudomonas_putida'] = lambda_df['Pseudomonas_putida']/lambda_df['Total']\n",
    "\n",
    "    lambda_df['label'] = 'vsearch'\n",
    "    lambda_df['numOtus'] = 4\n",
    "    lambda_df['Group'] = \"silico_%s\" % (label)\n",
    "\n",
    "    #for row_index in lambda_df.index:\n",
    "    #    lambda_df.iat[row_index,7] = row_index+1\n",
    "\n",
    "    #lambda_df = lambda_df.drop('Total', axis='columns')\n",
    "\n",
    "    shared_file_order = ['label', 'Group', 'numOtus', 'Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida' ]\n",
    "    lambda_df = lambda_df[shared_file_order]\n",
    "\n",
    "    return lambda_df\n",
    "\n",
    "def prevalence(df):\n",
    "    df.loc[:,'Bacillus_subtilis':'Pseudomonas_putida']=np.where(df.loc[:,'Bacillus_subtilis':'Pseudomonas_putida']>0,1,0)\n",
    "    tot_inst = df.shape[0]\n",
    "    df_prev_sums = df.loc[:,'Bacillus_subtilis':'Pseudomonas_putida'].sum()*100/tot_inst\n",
    "    return df_prev_sums\n",
    "\n",
    "def average_rel_abun(df):\n",
    "    df['Total'] = df.loc[:,'Bacillus_subtilis':'Pseudomonas_putida'].sum(axis=1)\n",
    "    df['Bacillus_subtilis'] = df['Bacillus_subtilis']*100/df['Total']\n",
    "    df['Escherichia_coli'] = df['Escherichia_coli']*100/df['Total']\n",
    "    df['Bacteroides_thetaiotaomicron'] = df['Bacteroides_thetaiotaomicron']*100/df['Total']\n",
    "    df['Pseudomonas_putida'] = df['Pseudomonas_putida']*100/df['Total']\n",
    "\n",
    "    avg_rel_abun = []\n",
    "    avg_rel_abun[0] = df[df['Bacillus_subtilis'] != 0]['Bacillus_subtilis'].mean()\n",
    "    avg_rel_abun[1] = df[df['Bacteroides_thetaiotaomicron'] != 0]['Bacteroides_thetaiotaomicron'].mean()\n",
    "    avg_rel_abun[2] = df[df['Escherichia_coli'] != 0]['Escherichia_coli'].mean()\n",
    "    avg_rel_abun[3] = df[df['Pseudomonas_putida'] != 0]['Pseudomonas_putida'].mean()\n",
    "\n",
    "    return\n",
    "\n",
    "#generate in silico mock community\n",
    "# Lambda values (in order of Bs, Bt, Ec, Pp)\n",
    "lambdas_even = [25, 25, 25, 25]\n",
    "lambdas_log1 = [0.8, 90, 0.2, 9]\n",
    "lambdas_log2 = [9, 0.2, 90, 0.8]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "silico_even_df = in_silico_mock(lambdas_even, \"even\", 1000, 42, 3)\n",
    "silico_log1_df = in_silico_mock(lambdas_log1, \"log1\", 1000, 42, 3)\n",
    "silico_log2_df = in_silico_mock(lambdas_log2, \"log2\", 1000, 42, 3)\n",
    "\n",
    "silico_even_df_prev_sums = prevalence(silico_even_df)\n",
    "silico_log1_df_prev_sums = prevalence(silico_log1_df)\n",
    "silico_log2_df_prev_sums = prevalence(silico_log2_df)\n",
    "\n",
    "prev_data  = {\n",
    "    'library': ['even_real', 'even_silico', 'log-1_real', 'log-1_silico', 'log-2_real', 'log-2_silico'],\n",
    "    'Bs': [0,0,0,0,0,0],\n",
    "    'Bt': [0,0,0,0,0,0],\n",
    "    'Ec': [0,0,0,0,0,0],\n",
    "    'Pp': [0,0,0,0,0,0]\n",
    "}\n",
    "\n",
    "prev_rar100_df = pd.DataFrame(prev_data)\n",
    "prev_rar100_df.iloc[1,1:5] = silico_even_df_prev_sums\n",
    "prev_rar100_df.iloc[3,1:5] = silico_log1_df_prev_sums\n",
    "prev_rar100_df.iloc[5,1:5] = silico_log2_df_prev_sums\n",
    "\n",
    "#process the real mock community data\n",
    "even_df = pd.read_csv('even/even.shared', delimiter = '\\t')\n",
    "log1_df = pd.read_csv('log1/log1.shared', delimiter = '\\t')\n",
    "log2_df = pd.read_csv('log2/log2.shared', delimiter = '\\t')\n",
    "                      \n",
    "even_df_prev_sums_rar100 = prevalence(even_df)\n",
    "log1_df_prev_sums_rar100 = prevalence(log1_df)\n",
    "log2_df_prev_sums_rar100 = prevalence(log2_df)\n",
    "\n",
    "prev_rar100_df.iloc[0,1:5] = even_df_prev_sums_rar100\n",
    "prev_rar100_df.iloc[2,1:5] = log1_df_prev_sums_rar100\n",
    "prev_rar100_df.iloc[4,1:5] = log2_df_prev_sums_rar100\n",
    "\n",
    "df_long = prev_rar100_df.melt(id_vars='library', var_name='Species', value_name='Prevalence(%)')\n",
    "print(df_long)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(3, 2))\n",
    "\n",
    "sns.scatterplot(data=df_long[df_long['library']=='even_real'], x=\"Species\", y=\"Prevalence(%)\",marker='o',ax=axes[0])\n",
    "sns.scatterplot(data=df_long[df_long['library']=='even_silico'], x=\"Species\", y=\"Prevalence(%)\",marker='X',ax=axes[0])\n",
    "axes[0].set_title('Even')\n",
    "axes[0].set_ylim(0, 110)\n",
    "\n",
    "sns.scatterplot(data=df_long[df_long['library']=='log-1_real'], x=\"Species\", y=\"Prevalence(%)\",marker='o',ax=axes[1])\n",
    "sns.scatterplot(data=df_long[df_long['library']=='log-1_silico'], x=\"Species\", y=\"Prevalence(%)\",marker='X',ax=axes[1])\n",
    "axes[1].set_title('Bt-biased')\n",
    "axes[1].set_ylim(0, 110)\n",
    "axes[1].set(yticklabels=[])\n",
    "axes[1].set(ylabel=None)\n",
    "\n",
    "sns.scatterplot(data=df_long[df_long['library']=='log-2_real'], x=\"Species\", y=\"Prevalence(%)\",marker='o',ax=axes[2])\n",
    "sns.scatterplot(data=df_long[df_long['library']=='log-2_silico'], x=\"Species\", y=\"Prevalence(%)\",marker='X',ax=axes[2])\n",
    "axes[2].set_title('Ec-biased')\n",
    "axes[2].set_ylim(0, 110)\n",
    "axes[2].set(yticklabels=[])\n",
    "axes[2].set(ylabel=None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mock_prevalence.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to nix this code chunk since I don't think it shows anything super informative and I just want to finish this manuscript\n",
    "\n",
    "This code chunk processes the data in a similar process to the above (also generating Poisson \"null model\" for comparison) but keeps the \"even\", and \"log\" samples separate and rarefies the data by specified percentages to demonstrate the effect of sequencing depth on the metrics of richness and prevalence of the rarer members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def in_silico_mock(lambdas, label, n_instances, seed, multiplier):\n",
    "# Generate Poisson-distributed data for each lambda\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    lambda_df = pd.DataFrame()\n",
    "\n",
    "    Bs_poisson = np.random.poisson(lambdas[0], n_instances)\n",
    "    Bt_poisson = np.random.poisson(lambdas[1], n_instances)\n",
    "    Ec_poisson = np.random.poisson(lambdas[2], n_instances)\n",
    "    Pp_poisson = np.random.poisson(lambdas[3], n_instances)\n",
    "    \n",
    "    # Create a DataFrame for the current lambda\n",
    "    # Multiply by 16S copy number to account for that\n",
    "    #Multiplier is for subsampling, to increase the number of events from all samples for normalization downstream\n",
    "    lambda_df['Bacillus_subtilis'] = Bs_poisson*10*multiplier\n",
    "    lambda_df['Bacteroides_thetaiotaomicron'] = Bt_poisson*5*multiplier\n",
    "    lambda_df['Escherichia_coli'] = Ec_poisson*7*multiplier\n",
    "    lambda_df['Pseudomonas_putida'] = Pp_poisson*7*multiplier\n",
    "\n",
    "    lambda_df['label'] = 'vsearch'\n",
    "    lambda_df['numOtus'] = 4\n",
    "    lambda_df['Group'] = \"silico_%s\" % (label)\n",
    "\n",
    "    shared_file_order = ['label', 'Group', 'numOtus', 'Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida']\n",
    "    lambda_df = lambda_df[shared_file_order]\n",
    "\n",
    "    return lambda_df\n",
    "\n",
    "def rarefy(df, group_name, rarefy_frac, sequencing_depth_threshold):\n",
    "    #Specify the columns with integer values\n",
    "    int_columns = df.columns[3:7]\n",
    "    abun_df = df[int_columns]\n",
    "    total_events = abun_df.sum().sum()\n",
    "\n",
    "    tuple_list = []\n",
    "\n",
    "    #iterate through the df and generate the list of locations\n",
    "    for index, row in abun_df.iterrows():\n",
    "        for col, value in row.items():\n",
    "            tuple_list.extend([(index,col)] * value)\n",
    "\n",
    "    #subsample\n",
    "    subsamp_list = random.sample(tuple_list, int(rarefy_frac * total_events))\n",
    "\n",
    "    #convert subsampled list back into a dataframe\n",
    "    rarefy_df = df.copy()\n",
    "    rarefy_df['label'] = 'vsearch'\n",
    "    rarefy_df['numOtus'] = 4\n",
    "    rarefy_df['Group'] = group_name\n",
    "    rarefy_df['Bacillus_subtilis'] = 0\n",
    "    rarefy_df['Bacteroides_thetaiotaomicron'] = 0\n",
    "    rarefy_df['Escherichia_coli'] = 0\n",
    "    rarefy_df['Pseudomonas_putida'] = 0\n",
    "\n",
    "    #populate rarefied df based off of tuple list\n",
    "    for entry in subsamp_list:\n",
    "        row_index, col_name = entry\n",
    "        rarefy_df.at[row_index,col_name] = rarefy_df.at[row_index,col_name] + 1\n",
    "\n",
    "    #remove empty samples and samples below the sequencing depth threshold\n",
    "    rarefy_df['Total'] = rarefy_df[['Bacillus_subtilis','Bacteroides_thetaiotaomicron','Escherichia_coli','Pseudomonas_putida']].sum(axis=1)\n",
    "    rarefy_df = rarefy_df[rarefy_df['Total'] != 0]\n",
    "    rarefy_df = rarefy_df[rarefy_df['Total'] >= sequencing_depth_threshold]\n",
    "    rarefy_df = rarefy_df.drop('Total', axis=1)\n",
    "    \n",
    "    return rarefy_df\n",
    "\n",
    "#process the real mock community data\n",
    "even_df = pd.read_csv('even/even.shared', delimiter = '\\t')\n",
    "log1_df = pd.read_csv('log1/log1.shared', delimiter = '\\t')\n",
    "log2_df = pd.read_csv('log2/log2.shared', delimiter = '\\t')\n",
    "\n",
    "#determine number of samples per sample\n",
    "num_even = len(even_df.index)\n",
    "num_log1 = len(log1_df.index)\n",
    "num_log2 = len(log2_df.index)\n",
    "                      \n",
    "#generate in silico mock community\n",
    "# Lambda values (in order of Bs, Bt, Ec, Pp)\n",
    "lambdas_even = [25, 25, 25, 25]\n",
    "lambdas_log1 = [0.8, 90, 0.2, 9]\n",
    "lambdas_log2 = [9, 0.2, 90, 0.8]\n",
    "\n",
    "silico_even_df = in_silico_mock(lambdas_even, \"even\", num_even, 42, 3)\n",
    "silico_log1_df = in_silico_mock(lambdas_log1, \"log1\", num_log1, 42, 3)\n",
    "silico_log2_df = in_silico_mock(lambdas_log2, \"log2\", num_log2, 42, 3)\n",
    "\n",
    "even_df['Group'] = 'even'\n",
    "log1_df['Group'] = 'log1'\n",
    "log2_df['Group'] = 'log2'\n",
    "\n",
    "#For testing\n",
    "# data = {'label': [0.03, 0.03, 0.03, 0.03],\n",
    "#         'Group': ['test','test','test','test'],\n",
    "#         'numOtus':[4,4,4,4],\n",
    "#         'Bacillus_subtilis':[0,40,90,0],\n",
    "#         'Bacteroides_thetaiotaomicron':[50,10,10,30],\n",
    "#         'Escherichia_coli':[0,50,0,70],\n",
    "#         'Pseudomonas_putida':[50,0,0,0]}\n",
    "# test_df = pd.DataFrame(data)\n",
    "\n",
    "log1_rarefy_10_df = rarefy(log1_df, 'log1_10', 0.1, 100)\n",
    "#log1_rarefy_25_df = rarefy(log1_df, 'log1_25', 0.25, 100)\n",
    "#log1_rarefy_50_df = rarefy(log1_df, 'log1_50', 0.50, 100)\n",
    "#log1_rarefy_100_df = rarefy(log1_df, 'log1_100', 100)\n",
    "\n",
    "print(log1_rarefy_10_df)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
